# -*- coding: utf-8 -*-
"""åŸºäºRedisçš„è‚¡ç¥¨APIæ¥å£"""

from fastapi import APIRouter, Depends, HTTPException, Query
from typing import Dict, Any, List, Optional
from datetime import datetime
import json
import asyncio
from pydantic import BaseModel

from app.core.redis_client import get_redis_client
from app.api.dependencies import verify_token
from app.core.logging import logger
from app.services.stock.redis_stock_service import get_stock_history

router = APIRouter(tags=["è‚¡ç¥¨æ•°æ®"])

# å®šä¹‰å“åº”æ¨¡å‹
class StockHistoryData(BaseModel):
    trade_date: str
    open: float
    high: float
    low: float
    close: float
    volume: Optional[float] = 0
    amount: Optional[float] = 0

class StockHistoryResponse(BaseModel):
    stock_code: str
    data: List[StockHistoryData]
    total: int

class StockPriceData(BaseModel):
    """è‚¡ç¥¨ä»·æ ¼æ•°æ®"""
    code: str
    name: Optional[str] = None
    price: Optional[float] = None
    change: Optional[float] = None
    change_percent: Optional[float] = None  # å‰ç«¯æœŸæœ›çš„å­—æ®µåæ˜¯ change_percent
    volume: Optional[float] = None  # æ·»åŠ æˆäº¤é‡å­—æ®µ
    error: Optional[str] = None

class BatchPriceResponse(BaseModel):
    """æ‰¹é‡ä»·æ ¼å“åº”"""
    success: bool
    total: int
    data: List[StockPriceData]
    timestamp: str

@router.get("/api/stocks", summary="è·å–æ‰€æœ‰è‚¡ç¥¨æ¸…å•", dependencies=[Depends(verify_token)])
async def get_stocks_list() -> Dict[str, Any]:
    """
    ä»Redisè·å–æ‰€æœ‰è‚¡ç¥¨æ¸…å•ï¼ˆä¸åˆ†é¡µï¼Œä¸€æ¬¡æ€§è¿”å›æ‰€æœ‰æ•°æ®ï¼‰
        
    Returns:
        æ‰€æœ‰è‚¡ç¥¨æ¸…å•åŠæ€»æ•°
    """
    redis_client = None
    try:
        # è·å–Redisè¿æ¥ - æ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°è·å–ï¼Œç¡®ä¿åœ¨æ­£ç¡®çš„äº‹ä»¶å¾ªç¯ä¸­
        redis_client = await get_redis_client()
        
        # è·å–è‚¡ç¥¨ä»£ç æ•°æ®
        stock_codes_key = "stocks:codes:all"
        stock_codes_data = await redis_client.get(stock_codes_key)
        
        if not stock_codes_data:
            raise HTTPException(status_code=500, detail="è‚¡ç¥¨ä»£ç æ•°æ®ä¸å¯ç”¨")
        
        stock_codes = json.loads(stock_codes_data)
        total = len(stock_codes)
        
        logger.info(f"ä¸€æ¬¡æ€§è¿”å›æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼Œå…± {total} åªè‚¡ç¥¨")
        
        return {
            "total": total,
            "returned": total,
            "stocks": stock_codes,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨æ¸…å•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨æ¸…å•å¤±è´¥: {str(e)}")



@router.get("/api/stocks/history", 
           response_model=StockHistoryResponse, 
           summary="è·å–è‚¡ç¥¨å†å²æ•°æ®", 
           dependencies=[Depends(verify_token)])
async def get_stock_history_data(
    stock_code: str = Query(..., description="è‚¡ç¥¨ä»£ç ")
) -> StockHistoryResponse:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨çš„å†å²è¡Œæƒ…æ•°æ®ï¼ˆä»Redisç¼“å­˜æˆ–å®æ—¶è·å–ï¼‰
    ä¿æŒä¸åŸæœ‰æ¥å£ç›¸åŒçš„å“åº”æ ¼å¼
    """
    try:
        logger.info(f"è·å–è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®")
        
        # é¦–å…ˆå°è¯•ä»Redisç¼“å­˜è·å–
        from app.api.data_validation import STOCK_KEYS
        
        # æ„é€ ts_code
        if stock_code.startswith('6'):
            ts_code = f"{stock_code}.SH"
        elif stock_code.startswith('5'):
            # 5å¼€å¤´æ˜¯ä¸Šæµ·ETFï¼ˆå¦‚510300ã€512880ã€560050ï¼‰
            ts_code = f"{stock_code}.SH"
        elif stock_code.startswith(('43', '83', '87', '88', '92')):
            # åŒ—äº¤æ‰€ï¼š43ã€83ã€87ã€88å¼€å¤´æ˜¯è‚¡ç¥¨ï¼Œ92å¼€å¤´æ˜¯æŒ‡æ•°
            ts_code = f"{stock_code}.BJ"
        else:
            ts_code = f"{stock_code}.SZ"
        
        cache_key = STOCK_KEYS['stock_kline'].format(ts_code)
        
        # ä½¿ç”¨åŒæ­¥Rediså®¢æˆ·ç«¯è·å–ç¼“å­˜æ•°æ®
        from app.db.session import RedisCache
        redis_cache = RedisCache()
        cached_data = redis_cache.get_cache(cache_key)
        
        if cached_data:
            # è½¬æ¢ç¼“å­˜æ•°æ®æ ¼å¼
            history_data = []
            
            # æ£€æŸ¥æ•°æ®ç±»å‹ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ™è§£æä¸ºJSON
            if isinstance(cached_data, str):
                try:
                    cached_data = json.loads(cached_data)
                except json.JSONDecodeError:
                    logger.error(f"ç¼“å­˜æ•°æ®JSONè§£æå¤±è´¥: {cached_data}")
                    cached_data = None
            
            # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
            if cached_data:
                kline_data = None
                
                if isinstance(cached_data, list):
                    # åŸå§‹listæ ¼å¼ï¼ˆåˆå§‹å†å²æ•°æ®ï¼‰
                    logger.info(f"å¤„ç†listæ ¼å¼çš„Kçº¿æ•°æ®ï¼Œå…± {len(cached_data)} æ¡")
                    kline_data = cached_data
                elif isinstance(cached_data, dict):
                    # æ–°çš„dictæ ¼å¼ï¼ˆå®æ—¶æ›´æ–°åçš„æ ¼å¼ï¼‰
                    logger.info(f"å¤„ç†dictæ ¼å¼çš„Kçº¿æ•°æ®")
                    kline_data = cached_data.get('data', [])
                    logger.info(f"ä»dictä¸­æå–dataå­—æ®µï¼Œå…± {len(kline_data)} æ¡")
                else:
                    logger.warning(f"æœªçŸ¥çš„ç¼“å­˜æ•°æ®æ ¼å¼: {type(cached_data)}")
                    cached_data = None
                
                # è½¬æ¢Kçº¿æ•°æ®ä¸ºAPIå“åº”æ ¼å¼
                if kline_data:
                    for item in kline_data:
                        # ç¡®ä¿itemæ˜¯å­—å…¸ç±»å‹
                        if isinstance(item, dict):
                            # æ™ºèƒ½å­—æ®µæ˜ å°„ï¼šå¤„ç†tushareå’Œakshareçš„ä¸åŒæ ¼å¼
                            trade_date_value = ''
                            volume_value = 0.0
                            
                            # å¤„ç†æ—¥æœŸå­—æ®µ
                            if 'trade_date' in item:
                                # tushareæ ¼å¼ï¼š20250102
                                trade_date_raw = str(item['trade_date'])
                                if len(trade_date_raw) == 8:
                                    trade_date_value = f"{trade_date_raw[:4]}-{trade_date_raw[4:6]}-{trade_date_raw[6:8]}"
                                else:
                                    trade_date_value = trade_date_raw
                            elif 'date' in item:
                                # akshareæ ¼å¼ï¼š2025-01-02
                                trade_date_value = str(item['date'])
                            elif 'actual_trade_date' in item:
                                # å®é™…äº¤æ˜“æ—¥æœŸ
                                trade_date_value = str(item['actual_trade_date'])[:10]
                            
                            # å¤„ç†æˆäº¤é‡å­—æ®µ
                            if 'vol' in item:
                                # tushareæ ¼å¼ï¼švol (å•ä½ï¼šæ‰‹ï¼Œéœ€è¦ä¹˜ä»¥100)
                                vol_raw = float(item['vol']) if item['vol'] else 0
                                volume_value = vol_raw * 100 if vol_raw > 0 else 0
                            elif 'volume' in item:
                                # akshareæ ¼å¼ï¼švolume (å•ä½ï¼šè‚¡)
                                volume_value = float(item['volume']) if item['volume'] else 0
                            
                            # å¤„ç†æˆäº¤é¢å­—æ®µ
                            amount_value = 0.0
                            if 'amount' in item:
                                # tushareæ ¼å¼ï¼šamount (å•ä½ï¼šåƒå…ƒï¼Œéœ€è¦ä¹˜ä»¥1000)
                                amount_raw = float(item['amount']) if item['amount'] else 0
                                # å¦‚æœé‡‘é¢å°äº1000000ï¼Œè®¤ä¸ºæ˜¯åƒå…ƒå•ä½ï¼Œéœ€è¦ä¹˜ä»¥1000
                                if amount_raw > 0 and amount_raw < 1000000:
                                    amount_value = amount_raw * 1000
                                else:
                                    amount_value = amount_raw
                            
                            history_data.append(StockHistoryData(
                                trade_date=trade_date_value,
                                open=float(item.get('open', 0)),
                                high=float(item.get('high', 0)),
                                low=float(item.get('low', 0)),
                                close=float(item.get('close', 0)),
                                volume=volume_value,
                                amount=amount_value
                            ))
                        else:
                            logger.warning(f"ç¼“å­˜æ•°æ®é¡¹æ ¼å¼é”™è¯¯: {type(item)} - {item}")
                else:
                    logger.warning(f"æ— æ³•ä»ç¼“å­˜ä¸­æå–Kçº¿æ•°æ®")
                    cached_data = None
            
            # åªæœ‰å½“æˆåŠŸè§£æåˆ°å†å²æ•°æ®æ—¶æ‰è¿”å›ç¼“å­˜ç»“æœ
            if history_data:
                logger.info(f"ä»Redisç¼“å­˜è·å–åˆ°è‚¡ç¥¨{stock_code} çš„{len(history_data)} æ¡å†å²æ•°æ®")
                
                return StockHistoryResponse(
                    stock_code=stock_code,
                    data=history_data,
                    total=len(history_data)
                )
            else:
                logger.warning(f"ç¼“å­˜æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œå°†å®æ—¶è·å–è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®")
        
        # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œå®æ—¶è·å–
        logger.info(f"ç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œå®æ—¶è·å–è‚¡ç¥¨ {stock_code} çš„å†å²æ•°æ®")
        
        history_result = get_stock_history(stock_code, days=180)
        
        if 'error' in history_result:
            raise HTTPException(status_code=500, detail=history_result['error'])
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        history_data = []
        for item in history_result.get('data', []):
            # æ™ºèƒ½å­—æ®µæ˜ å°„ï¼šå¤„ç†tushareå’Œakshareçš„ä¸åŒæ ¼å¼
            trade_date_value = ''
            volume_value = 0.0
            
            # å¤„ç†æ—¥æœŸå­—æ®µ
            if 'trade_date' in item:
                # tushareæ ¼å¼ï¼š20250102
                trade_date_raw = str(item['trade_date'])
                if len(trade_date_raw) == 8:
                    trade_date_value = f"{trade_date_raw[:4]}-{trade_date_raw[4:6]}-{trade_date_raw[6:8]}"
                else:
                    trade_date_value = trade_date_raw
            elif 'date' in item:
                # akshareæ ¼å¼ï¼š2025-01-02
                trade_date_value = str(item['date'])
            elif 'actual_trade_date' in item:
                # å®é™…äº¤æ˜“æ—¥æœŸ
                trade_date_value = str(item['actual_trade_date'])[:10]
            
            # å¤„ç†æˆäº¤é‡å­—æ®µ
            if 'vol' in item:
                # tushareæ ¼å¼ï¼švol (å•ä½ï¼šæ‰‹ï¼Œéœ€è¦ä¹˜ä»¥100)
                vol_raw = float(item['vol']) if item['vol'] else 0
                volume_value = vol_raw * 100 if vol_raw > 0 else 0
            elif 'volume' in item:
                # akshareæ ¼å¼ï¼švolume (å•ä½ï¼šè‚¡)
                volume_value = float(item['volume']) if item['volume'] else 0
            
            # å¤„ç†æˆäº¤é¢å­—æ®µ
            amount_value = 0.0
            if 'amount' in item:
                # tushareæ ¼å¼ï¼šamount (å•ä½ï¼šåƒå…ƒï¼Œéœ€è¦ä¹˜ä»¥1000)
                amount_raw = float(item['amount']) if item['amount'] else 0
                # å¦‚æœé‡‘é¢å°äº1000000ï¼Œè®¤ä¸ºæ˜¯åƒå…ƒå•ä½ï¼Œéœ€è¦ä¹˜ä»¥1000
                if amount_raw > 0 and amount_raw < 1000000:
                    amount_value = amount_raw * 1000
                else:
                    amount_value = amount_raw
            
            history_data.append(StockHistoryData(
                trade_date=trade_date_value,
                open=float(item.get('open', 0)),
                high=float(item.get('high', 0)),
                low=float(item.get('low', 0)),
                close=float(item.get('close', 0)),
                volume=volume_value,
                amount=amount_value
            ))
        
        # ç¼“å­˜æ•°æ®
        if history_data:
            redis_cache.set_cache(cache_key, history_result.get('data', []), ttl=86400)  # ç¼“å­˜1å¤©
        
        logger.info(f"å®æ—¶è·å–åˆ°è‚¡ç¥¨{stock_code} çš„{len(history_data)} æ¡å†å²æ•°æ®")
        
        return StockHistoryResponse(
            stock_code=stock_code,
            data=history_data,
            total=len(history_data)
        )
        
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨å†å²æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨å†å²æ•°æ®å¤±è´¥: {str(e)}")


@router.get("/api/stocks/batch-price",
           response_model=BatchPriceResponse,
           summary="æ‰¹é‡è·å–è‚¡ç¥¨æœ€æ–°ä»·æ ¼",
           dependencies=[Depends(verify_token)])
async def get_batch_stock_price(
    codes: str = Query(..., description="è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚: 000001,600000,300001")
) -> BatchPriceResponse:
    """
    æ‰¹é‡è·å–è‚¡ç¥¨æœ€æ–°ä»·æ ¼
    
    ä¼˜å…ˆä»Redisç¼“å­˜è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™å®æ—¶ä»Tushareè·å–
    
    Args:
        codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé€—å·åˆ†éš”
    
    Returns:
        æ‰¹é‡ä»·æ ¼æ•°æ®
    """
    try:
        # è§£æè‚¡ç¥¨ä»£ç åˆ—è¡¨
        code_list = [code.strip() for code in codes.split(',') if code.strip()]
        
        if not code_list:
            raise HTTPException(status_code=400, detail="è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        if len(code_list) > 100:
            raise HTTPException(status_code=400, detail="å•æ¬¡æœ€å¤šæŸ¥è¯¢100åªè‚¡ç¥¨")
        
        logger.info(f"æ‰¹é‡è·å– {len(code_list)} åªè‚¡ç¥¨çš„ä»·æ ¼: {code_list}")
        
        # ä½¿ç”¨Redisç¼“å­˜è·å–æ•°æ®
        from app.db.session import RedisCache
        redis_cache = RedisCache()
        
        result_data = []
        codes_need_realtime = []  # éœ€è¦å®æ—¶è·å–çš„è‚¡ç¥¨ä»£ç 
        
        for code in code_list:
            try:
                # æ„é€ ts_code
                if code.startswith('6'):
                    ts_code = f"{code}.SH"
                elif code.startswith('5'):
                    # 5å¼€å¤´æ˜¯ä¸Šæµ·ETFï¼ˆå¦‚510300ã€512880ã€560050ï¼‰
                    ts_code = f"{code}.SH"
                elif code.startswith(('43', '83', '87', '88', '92')):
                    # åŒ—äº¤æ‰€ï¼š43ã€83ã€87ã€88å¼€å¤´æ˜¯è‚¡ç¥¨ï¼Œ92å¼€å¤´æ˜¯æŒ‡æ•°
                    ts_code = f"{code}.BJ"
                else:
                    ts_code = f"{code}.SZ"
                
                # ä»Redisè·å–Kçº¿æ•°æ®
                cache_key = f"stock_trend:{ts_code}"
                cached_data = redis_cache.get_cache(cache_key)
                
                if not cached_data:
                    # è®°å½•éœ€è¦å®æ—¶è·å–çš„è‚¡ç¥¨
                    codes_need_realtime.append((code, ts_code))
                    continue
                
                # è§£æç¼“å­˜æ•°æ®
                kline_data = None
                if isinstance(cached_data, list):
                    kline_data = cached_data
                elif isinstance(cached_data, dict):
                    kline_data = cached_data.get('data', [])
                
                if not kline_data or len(kline_data) == 0:
                    codes_need_realtime.append((code, ts_code))
                    continue
                
                # è·å–æœ€æ–°ä¸€æ¡Kçº¿æ•°æ®
                latest = kline_data[-1]
                
                # æå–ä»·æ ¼ä¿¡æ¯
                close_price = float(latest.get('close', 0))
                pre_close = float(latest.get('pre_close', 0))
                
                # è®¡ç®—æ¶¨è·Œ
                change = 0.0
                change_percent = 0.0
                if pre_close > 0:
                    change = close_price - pre_close
                    change_percent = (change / pre_close) * 100
                
                # è·å–æˆäº¤é‡
                volume = float(latest.get('vol', 0)) * 100  # volæ˜¯æ‰‹ï¼Œè½¬ä¸ºè‚¡
                
                # è·å–è‚¡ç¥¨åç§°ï¼ˆä»è‚¡ç¥¨åˆ—è¡¨ä¸­æŸ¥æ‰¾ï¼‰
                stock_name = None
                try:
                    stock_codes_data = redis_cache.get_cache("stocks:codes:all")
                    if stock_codes_data:
                        if isinstance(stock_codes_data, str):
                            stock_codes = json.loads(stock_codes_data)
                        else:
                            stock_codes = stock_codes_data
                        
                        for stock in stock_codes:
                            if stock.get('symbol') == code or stock.get('ts_code') == ts_code:
                                stock_name = stock.get('name')
                                break
                except Exception as e:
                    logger.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
                
                result_data.append(StockPriceData(
                    code=code,
                    name=stock_name,
                    price=close_price,
                    change=round(change, 2),
                    change_percent=round(change_percent, 2),
                    volume=volume if volume > 0 else None
                ))
                
            except Exception as e:
                logger.error(f"è·å–è‚¡ç¥¨ {code} ä»·æ ¼å¤±è´¥: {e}")
                result_data.append(StockPriceData(
                    code=code,
                    error=str(e)
                ))
        
        # å¯¹äºRedisä¸­æ²¡æœ‰æ•°æ®çš„è‚¡ç¥¨ï¼Œå°è¯•ä»Tushareå®æ—¶è·å–
        if codes_need_realtime:
            logger.info(f"ğŸ”„ éœ€è¦å®æ—¶è·å– {len(codes_need_realtime)} åªè‚¡ç¥¨çš„ä»·æ ¼")
            realtime_results = await _fetch_realtime_prices(codes_need_realtime, redis_cache)
            result_data.extend(realtime_results)
        
        logger.info(f"æ‰¹é‡è·å–ä»·æ ¼å®Œæˆï¼ŒæˆåŠŸ {sum(1 for d in result_data if d.price is not None)} åª")
        
        return BatchPriceResponse(
            success=True,
            total=len(result_data),
            data=result_data,
            timestamp=datetime.now().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡è·å–è‚¡ç¥¨ä»·æ ¼å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è·å–è‚¡ç¥¨ä»·æ ¼å¤±è´¥: {str(e)}")


async def _fetch_realtime_prices(codes_list: list, redis_cache) -> list:
    """
    ä»Tushareå®æ—¶è·å–è‚¡ç¥¨ä»·æ ¼
    
    Args:
        codes_list: [(code, ts_code), ...] è‚¡ç¥¨ä»£ç åˆ—è¡¨
        redis_cache: Redisç¼“å­˜å®ä¾‹
    
    Returns:
        StockPriceDataåˆ—è¡¨
    """
    result_data = []
    
    try:
        import tushare as ts
        from app.core.config import settings
        
        # åˆå§‹åŒ–tushare
        pro = ts.pro_api(settings.TUSHARE_TOKEN)
        
        # è·å–æœ€è¿‘äº¤æ˜“æ—¥
        from datetime import datetime, timedelta
        today = datetime.now()
        start_date = (today - timedelta(days=10)).strftime('%Y%m%d')
        end_date = today.strftime('%Y%m%d')
        
        for code, ts_code in codes_list:
            try:
                # è·å–æœ€è¿‘çš„æ—¥çº¿æ•°æ®
                df = pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)
                
                if df is None or df.empty:
                    logger.warning(f"Tushareæœªè¿”å› {ts_code} çš„æ•°æ®")
                    result_data.append(StockPriceData(
                        code=code,
                        error="æš‚æ— äº¤æ˜“æ•°æ®"
                    ))
                    continue
                
                # è·å–æœ€æ–°ä¸€æ¡æ•°æ®
                latest = df.iloc[0]
                
                close_price = float(latest['close'])
                pre_close = float(latest['pre_close'])
                
                # è®¡ç®—æ¶¨è·Œ
                change = 0.0
                change_percent = 0.0
                if pre_close > 0:
                    change = close_price - pre_close
                    change_percent = (change / pre_close) * 100
                
                # è·å–æˆäº¤é‡
                volume = float(latest.get('vol', 0)) * 100  # volæ˜¯æ‰‹ï¼Œè½¬ä¸ºè‚¡
                
                # è·å–è‚¡ç¥¨åç§°
                stock_name = None
                try:
                    stock_codes_data = redis_cache.get_cache("stocks:codes:all")
                    if stock_codes_data:
                        if isinstance(stock_codes_data, str):
                            stock_codes = json.loads(stock_codes_data)
                        else:
                            stock_codes = stock_codes_data
                        
                        for stock in stock_codes:
                            if stock.get('symbol') == code or stock.get('ts_code') == ts_code:
                                stock_name = stock.get('name')
                                break
                except Exception as e:
                    logger.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
                
                result_data.append(StockPriceData(
                    code=code,
                    name=stock_name,
                    price=close_price,
                    change=round(change, 2),
                    change_percent=round(change_percent, 2),
                    volume=volume if volume > 0 else None
                ))
                
                logger.info(f"âœ… å®æ—¶è·å– {ts_code} ä»·æ ¼æˆåŠŸ: {close_price}")
                
                # åŒæ—¶ç¼“å­˜åˆ°Redisï¼Œé¿å…ä¸‹æ¬¡å†æŸ¥è¯¢
                try:
                    kline_list = []
                    for _, row in df.iterrows():
                        kline_list.append({
                            'trade_date': row['trade_date'],
                            'open': float(row['open']),
                            'high': float(row['high']),
                            'low': float(row['low']),
                            'close': float(row['close']),
                            'pre_close': float(row['pre_close']),
                            'vol': float(row['vol']),
                            'amount': float(row['amount']),
                        })
                    
                    # æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
                    kline_list.reverse()
                    
                    cache_data = {
                        'ts_code': ts_code,
                        'data': kline_list,
                        'updated_at': datetime.now().isoformat(),
                        'data_count': len(kline_list),
                        'source': 'tushare_realtime'
                    }
                    
                    cache_key = f"stock_trend:{ts_code}"
                    redis_cache.set_cache(cache_key, cache_data, expire=3600)  # ç¼“å­˜1å°æ—¶
                    logger.info(f"ğŸ“¦ å·²ç¼“å­˜ {ts_code} çš„Kçº¿æ•°æ®")
                    
                except Exception as cache_error:
                    logger.warning(f"ç¼“å­˜ {ts_code} æ•°æ®å¤±è´¥: {cache_error}")
                
            except Exception as e:
                logger.error(f"å®æ—¶è·å– {ts_code} ä»·æ ¼å¤±è´¥: {e}")
                result_data.append(StockPriceData(
                    code=code,
                    error=f"è·å–å¤±è´¥: {str(e)}"
                ))
    
    except ImportError:
        logger.error("Tushareæœªå®‰è£…ï¼Œæ— æ³•å®æ—¶è·å–ä»·æ ¼")
        for code, ts_code in codes_list:
            result_data.append(StockPriceData(
                code=code,
                error="æœåŠ¡æš‚ä¸å¯ç”¨"
            ))
    except Exception as e:
        logger.error(f"å®æ—¶è·å–ä»·æ ¼å¤±è´¥: {e}")
        for code, ts_code in codes_list:
            result_data.append(StockPriceData(
                code=code,
                error=f"è·å–å¤±è´¥: {str(e)}"
            ))
    
    return result_data


# ==================== å¤šå‘¨æœŸKçº¿API ====================

class MultiPeriodKlineData(BaseModel):
    """å¤šå‘¨æœŸKçº¿æ•°æ®é¡¹"""
    date: str
    open: float
    high: float
    low: float
    close: float
    volume: float
    amount: Optional[float] = None
    change_pct: Optional[float] = None


class MultiPeriodKlineResponse(BaseModel):
    """å¤šå‘¨æœŸKçº¿å“åº”"""
    success: bool
    data: Optional[List[MultiPeriodKlineData]] = None
    period: Optional[str] = None
    period_name: Optional[str] = None
    count: Optional[int] = None
    from_cache: Optional[bool] = None
    error: Optional[str] = None


class SupportedPeriodsResponse(BaseModel):
    """æ”¯æŒçš„å‘¨æœŸåˆ—è¡¨å“åº”"""
    success: bool
    periods: Dict[str, str]


@router.get("/api/stocks/{stock_code}/kline",
           response_model=MultiPeriodKlineResponse,
           summary="è·å–å¤šå‘¨æœŸKçº¿æ•°æ®",
           dependencies=[Depends(verify_token)])
async def get_multi_period_kline(
    stock_code: str,
    period: str = Query(
        default="daily",
        description="Kçº¿å‘¨æœŸ: daily(æ—¥çº¿), weekly(å‘¨çº¿), monthly(æœˆçº¿), 15min(15åˆ†é’Ÿ), 30min(30åˆ†é’Ÿ), 60min(60åˆ†é’Ÿ)"
    ),
    limit: int = Query(
        default=200,
        ge=10,
        le=500,
        description="è¿”å›æ•°æ®æ¡æ•°ï¼ŒèŒƒå›´10-500"
    )
) -> MultiPeriodKlineResponse:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨çš„å¤šå‘¨æœŸKçº¿æ•°æ®
    
    æ”¯æŒçš„å‘¨æœŸï¼š
    - daily: æ—¥çº¿ï¼ˆæ•°æ®æºï¼šTushareï¼‰
    - weekly: å‘¨çº¿ï¼ˆæ•°æ®æºï¼šAKShareï¼‰
    - monthly: æœˆçº¿ï¼ˆæ•°æ®æºï¼šAKShareï¼‰
    - 15min: 15åˆ†é’Ÿï¼ˆæ•°æ®æºï¼šAKShareï¼‰
    - 30min: 30åˆ†é’Ÿï¼ˆæ•°æ®æºï¼šAKShareï¼‰
    - 60min: 60åˆ†é’Ÿï¼ˆæ•°æ®æºï¼šAKShareï¼‰
    
    ç¼“å­˜ç­–ç•¥ï¼š
    - æ—¥çº¿ï¼š24å°æ—¶
    - å‘¨çº¿ï¼š1å°æ—¶ï¼ˆéäº¤æ˜“æ—¶é—´24å°æ—¶ï¼‰
    - æœˆçº¿ï¼š2å°æ—¶ï¼ˆéäº¤æ˜“æ—¶é—´24å°æ—¶ï¼‰
    - åˆ†é’Ÿçº§ï¼š5-15åˆ†é’Ÿï¼ˆéäº¤æ˜“æ—¶é—´1å°æ—¶ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001 æˆ– 000001.SZï¼‰
        period: Kçº¿å‘¨æœŸ
        limit: è¿”å›æ•°æ®æ¡æ•°
        
    Returns:
        Kçº¿æ•°æ®åˆ—è¡¨
    """
    try:
        from app.services.stock.multi_period_kline_service import multi_period_kline_service
        
        logger.info(f"è·å– {stock_code} {period} Kçº¿æ•°æ®ï¼Œlimit={limit}")
        
        result = await multi_period_kline_service.get_kline_data(
            stock_code=stock_code,
            period=period,
            limit=limit
        )
        
        if not result['success']:
            return MultiPeriodKlineResponse(
                success=False,
                error=result.get('error', 'è·å–Kçº¿æ•°æ®å¤±è´¥')
            )
        
        return MultiPeriodKlineResponse(
            success=True,
            data=result['data'],
            period=result['period'],
            period_name=result['period_name'],
            count=result['count'],
            from_cache=result.get('from_cache', False)
        )
        
    except Exception as e:
        logger.error(f"è·å–å¤šå‘¨æœŸKçº¿æ•°æ®å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return MultiPeriodKlineResponse(
            success=False,
            error=f"è·å–Kçº¿æ•°æ®å¤±è´¥: {str(e)}"
        )


@router.get("/api/stocks/kline/periods",
           response_model=SupportedPeriodsResponse,
           summary="è·å–æ”¯æŒçš„Kçº¿å‘¨æœŸåˆ—è¡¨",
           dependencies=[Depends(verify_token)])
async def get_supported_periods() -> SupportedPeriodsResponse:
    """
    è·å–æ”¯æŒçš„Kçº¿å‘¨æœŸåˆ—è¡¨
    
    Returns:
        æ”¯æŒçš„å‘¨æœŸå­—å…¸ï¼Œkeyä¸ºå‘¨æœŸä»£ç ï¼Œvalueä¸ºå‘¨æœŸåç§°
    """
    try:
        from app.services.stock.multi_period_kline_service import multi_period_kline_service
        
        periods = multi_period_kline_service.get_supported_periods()
        
        return SupportedPeriodsResponse(
            success=True,
            periods=periods
        )
        
    except Exception as e:
        logger.error(f"è·å–æ”¯æŒçš„å‘¨æœŸåˆ—è¡¨å¤±è´¥: {e}")
        return SupportedPeriodsResponse(
            success=False,
            periods={}
        )