# 全量更新失败率优化方案

## 问题分析

### 原有问题

1. **并发数过高导致API限流**
   - 初始并发数 `max_concurrent=10`，容易触发Tushare API限流
   - 批量处理时大量并发请求导致20%左右的失败率

2. **补偿机制不完善**
   - 只补偿一次，如果补偿失败就不再重试
   - 补偿时的并发数仍然较高（5），可能再次触发限流
   - 没有记录最终失败的股票代码

3. **缺少详细的失败追踪**
   - 无法追踪哪些股票最终获取失败
   - 没有补偿轮次的详细记录

## 优化方案

### 1. 降低初始并发数

**修改位置**: `stock_scheduler.py`

```python
# 优化前
max_concurrent=10

# 优化后
max_concurrent=5  # 降低并发数，减少API限流
```

**效果**:
- 减少同时发起的API请求数量
- 降低触发限流的概率
- 预期失败率从20%降至5%以下

### 2. 多轮补偿机制

**修改位置**: `stock_atomic_service.py` - `full_update_all_stocks()`

**优化内容**:

#### 2.1 多轮重试
```python
max_compensation_rounds = 3  # 最多补偿3轮
```

- 第1轮：并发数 = max_concurrent // 2 = 2-3
- 第2轮：并发数 = max_concurrent // 4 = 1-2
- 第3轮：并发数 = max_concurrent // 8 = 1

#### 2.2 逐轮降低并发数
```python
compensation_concurrent = max(1, max_concurrent // (2 ** round_num))
```

**并发数变化**:
- 初始: 5个并发
- 第1轮补偿: 2个并发
- 第2轮补偿: 1个并发
- 第3轮补偿: 1个并发

#### 2.3 增加等待时间
```python
wait_time = 5 * round_num  # 根据轮次增加等待时间
```

**等待时间**:
- 第1轮: 5秒
- 第2轮: 10秒
- 第3轮: 15秒

### 3. 详细的失败追踪

#### 3.1 记录补偿详情
```python
compensation_rounds = [
    {
        'round': 1,
        'attempted': 100,
        'success': 80,
        'failed': 20
    },
    {
        'round': 2,
        'attempted': 20,
        'success': 15,
        'failed': 5
    },
    ...
]
```

#### 3.2 记录最终失败的股票
```python
result['final_failed_stocks'] = ['600000.SH', '000001.SZ', ...]
```

#### 3.3 详细的日志输出
```python
logger.error(f"最终仍有 {len(failed_codes)} 只股票获取失败: {', '.join(failed_codes[:10])}")
```

## 优化效果预期

### 成功率提升

| 阶段 | 预期成功率 | 说明 |
|------|-----------|------|
| 初始获取 | 95% | 降低并发数后 |
| 第1轮补偿 | +3% | 补偿80%的失败 |
| 第2轮补偿 | +1.5% | 补偿75%的失败 |
| 第3轮补偿 | +0.5% | 补偿50%的失败 |
| **最终成功率** | **≥99.5%** | 综合效果 |

### 性能影响

| 指标 | 优化前 | 优化后 | 变化 |
|------|--------|--------|------|
| 初始并发数 | 10 | 5 | -50% |
| 初始失败率 | ~20% | ~5% | -75% |
| 补偿轮次 | 1轮 | 最多3轮 | +200% |
| 最终成功率 | ~80% | ≥99.5% | +24% |
| 总耗时 | ~10分钟 | ~12-15分钟 | +20-50% |

**说明**:
- 虽然总耗时略有增加，但成功率大幅提升
- 减少了需要手动处理失败股票的工作量
- 提供了详细的失败追踪，便于问题排查

## 使用示例

### 1. 查看补偿详情

```python
result = await stock_atomic_service.full_update_all_stocks(days=180)

# 查看补偿轮次
for round_info in result.get('compensation_rounds', []):
    print(f"第 {round_info['round']} 轮: "
          f"尝试 {round_info['attempted']}, "
          f"成功 {round_info['success']}, "
          f"失败 {round_info['failed']}")

# 查看最终失败的股票
final_failed = result.get('final_failed_stocks', [])
if final_failed:
    print(f"最终失败的股票: {', '.join(final_failed)}")
```

### 2. 日志输出示例

```
[INFO] 开始全量更新所有股票K线数据，天数=180天...
[INFO] 需要更新 5000 只股票的K线数据
[INFO] 处理第 1/100 批，共 50 只股票
[INFO] 第 1 批完成: 成功 48/50, 失败 2/50, 累计成功 48/5000
...
[WARNING] 第 1 轮补偿: 检测到 250 只股票获取失败，开始重试...
[INFO] 等待 5 秒让API限制恢复...
[INFO] 第 1 轮补偿: 开始重试 250 只失败股票（并发数=2）...
[INFO] 第 1 轮补偿完成: 重试 250 只, 成功 200 只, 仍失败 50 只
[WARNING] 第 2 轮补偿: 检测到 50 只股票获取失败，开始重试...
[INFO] 等待 10 秒让API限制恢复...
[INFO] 第 2 轮补偿: 开始重试 50 只失败股票（并发数=1）...
[INFO] 第 2 轮补偿完成: 重试 50 只, 成功 40 只, 仍失败 10 只
[WARNING] 第 3 轮补偿: 检测到 10 只股票获取失败，开始重试...
[INFO] 等待 15 秒让API限制恢复...
[INFO] 第 3 轮补偿: 开始重试 10 只失败股票（并发数=1）...
[INFO] 第 3 轮补偿完成: 重试 10 只, 成功 8 只, 仍失败 2 只
[ERROR] 最终仍有 2 只股票获取失败: 600000.SH, 000001.SZ
[INFO] 全量更新完成: 总计=5000, 成功=4998, 失败=2, 成功率=99.96%, 耗时=12.5分钟
```

## 配置参数

### 环境变量（可选）

可以通过环境变量调整参数：

```yaml
# docker-compose.yml
environment:
  # 全量更新配置
  - FULL_UPDATE_MAX_CONCURRENT=5      # 最大并发数（默认5）
  - FULL_UPDATE_BATCH_SIZE=50         # 批次大小（默认50）
  - FULL_UPDATE_MAX_COMPENSATION=3    # 最大补偿轮次（默认3）
```

### 代码配置

```python
# 在调用时指定参数
result = await stock_atomic_service.full_update_all_stocks(
    days=180,
    batch_size=50,          # 每批处理的股票数量
    max_concurrent=5        # 最大并发数
)
```

## 故障排查

### 问题1: 仍有较高失败率

**可能原因**:
1. Tushare API积分不足
2. 网络不稳定
3. 并发数仍然过高

**解决方案**:
```python
# 进一步降低并发数
result = await stock_atomic_service.full_update_all_stocks(
    days=180,
    max_concurrent=3  # 降至3
)
```

### 问题2: 更新时间过长

**可能原因**:
1. 补偿轮次过多
2. 等待时间过长
3. 股票数量过多

**解决方案**:
```python
# 调整批次大小和并发数的平衡
result = await stock_atomic_service.full_update_all_stocks(
    days=180,
    batch_size=100,      # 增加批次大小
    max_concurrent=5     # 保持适中的并发数
)
```

### 问题3: 特定股票总是失败

**排查步骤**:
1. 查看日志中的失败股票代码
2. 手动测试这些股票的API调用
3. 检查是否是退市或停牌股票

**处理方案**:
```python
# 查看最终失败的股票
final_failed = result.get('final_failed_stocks', [])
for code in final_failed:
    logger.info(f"手动检查股票: {code}")
    # 可以手动调用API测试
```

## 监控指标

### 关键指标

1. **初始成功率**: 第一次批量获取的成功率
2. **补偿成功率**: 每轮补偿的成功率
3. **最终成功率**: 所有补偿后的最终成功率
4. **总耗时**: 从开始到结束的总时间
5. **失败股票数**: 最终仍然失败的股票数量

### 告警阈值

| 指标 | 正常 | 警告 | 严重 |
|------|------|------|------|
| 初始成功率 | ≥95% | 90-95% | <90% |
| 最终成功率 | ≥99% | 95-99% | <95% |
| 总耗时 | <15分钟 | 15-20分钟 | >20分钟 |
| 失败股票数 | ≤10 | 10-50 | >50 |

## 后续优化建议

### 短期（1周内）

1. **监控和调优**
   - 收集实际运行数据
   - 根据失败率调整并发数
   - 优化等待时间

2. **错误分类**
   - 区分API限流、网络错误、数据错误
   - 针对不同错误类型采取不同策略

### 中期（1个月内）

1. **智能重试**
   - 根据错误类型决定是否重试
   - 对永久性错误（如退市股票）不再重试

2. **缓存机制**
   - 缓存成功获取的数据
   - 避免重复获取

3. **增量更新**
   - 只更新有变化的股票
   - 减少不必要的API调用

### 长期（3个月内）

1. **分布式处理**
   - 使用多个API Token
   - 分布式并发获取

2. **预测性维护**
   - 分析失败模式
   - 预测可能失败的股票
   - 提前采取措施

## 总结

本次优化主要解决了全量更新失败率高和缺少补偿机制的问题：

✅ **降低并发数**: 从10降至5，减少API限流
✅ **多轮补偿**: 最多3轮，逐轮降低并发数
✅ **详细追踪**: 记录每轮补偿详情和最终失败股票
✅ **成功率提升**: 预期从80%提升至99.5%以上

**预期效果**:
- 失败率从20%降至0.5%以下
- 提供详细的失败追踪和补偿记录
- 虽然总耗时略有增加，但大幅减少手动处理工作量

---

**更新时间**: 2025-11-11  
**版本**: v2.0.0

